version: "3.8"

services:
  py-crawler:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: mercari-py-crawler
    restart: unless-stopped
    environment:
      # Redis connection (use host.docker.internal on Mac/Windows, or redis service)
      - REDIS_ADDR=${REDIS_ADDR:-redis:6379}
      - REDIS_PASSWORD=${REDIS_PASSWORD:-}
      # Rate limiting (must match Go analyzer settings)
      - APP_RATE_LIMIT=${APP_RATE_LIMIT:-5}
      - APP_RATE_BURST=${APP_RATE_BURST:-10}
      # Token settings
      - TOKEN_MAX_AGE_MINUTES=${TOKEN_MAX_AGE_MINUTES:-30}
      # Crawler settings
      - CRAWLER_MAX_CONCURRENT_TASKS=${CRAWLER_MAX_CONCURRENT_TASKS:-3}
      # Ports
      - HEALTH_PORT=${HEALTH_PORT:-8081}
      - METRICS_PORT=${METRICS_PORT:-2113}
    ports:
      - "8081:8081"   # Health check
      - "2113:2113"   # Prometheus metrics
    networks:
      - animetop-network
    # Memory limit (target ~500MB)
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 256M
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

networks:
  animetop-network:
    external: true
