# =============================================================================
# Spot ASG Scaler - æ›¿ä»£ Cluster Autoscaler
# K3s ä¸å…¼å®¹ Cluster Autoscalerï¼Œä½¿ç”¨ CronJob è½®è¯¢æ–¹å¼
# =============================================================================
#
# å‰ç½®æ¡ä»¶ï¼šåœ¨ kube-system å‘½åç©ºé—´åˆ›å»º Secrets
#
# 1. AWS å‡­è¯ (å¿…éœ€)
# kubectl create secret generic aws-credentials \
#   --from-literal=AWS_ACCESS_KEY_ID=xxx \
#   --from-literal=AWS_SECRET_ACCESS_KEY=xxx \
#   -n kube-system
#
# 2. Tailscale API Key (å¯é€‰ï¼Œç”¨äºæ¸…ç† offline èŠ‚ç‚¹)
#    åœ¨ https://login.tailscale.com/admin/settings/keys åˆ›å»º API key
#    æƒé™: Devices - Read, Write
# kubectl create secret generic tailscale-api \
#   --from-literal=api-key=tskey-api-xxx \
#   -n kube-system
#
# =============================================================================

# RBAC
apiVersion: v1
kind: ServiceAccount
metadata:
  name: spot-asg-scaler
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: spot-asg-scaler
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list", "watch"]
- apiGroups: [""]
  resources: ["nodes"]
  verbs: ["get", "list", "watch", "delete"]
- apiGroups: ["apps"]
  resources: ["deployments"]
  verbs: ["get", "list"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: spot-asg-scaler
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: spot-asg-scaler
subjects:
- kind: ServiceAccount
  name: spot-asg-scaler
  namespace: kube-system

---
# ConfigMap with scaling script
apiVersion: v1
kind: ConfigMap
metadata:
  name: spot-asg-scaler-script
  namespace: kube-system
data:
  scale.sh: |
    #!/bin/bash
    set -e

    ASG_NAME="py-crawler-spot-asg"
    AWS_REGION="ap-northeast-1"
    REDIS_HOST="100.99.127.100"
    REDIS_DEATHS_KEY="animetop:crawler:deaths"

    echo "=== Spot ASG Scaler $(date) ==="

    # =========================================================
    # 1. æ”¶é›†çŠ¶æ€
    # =========================================================

    # KEDA æ§åˆ¶çš„ deployment replicas
    KEDA_REPLICAS=$(kubectl get deployment py-crawler -n animehot -o jsonpath='{.spec.replicas}' 2>/dev/null || echo "0")
    KEDA_REPLICAS=${KEDA_REPLICAS:-0}

    # Pending pods (éœ€è¦èŠ‚ç‚¹æ¥è°ƒåº¦)
    PENDING_PODS=$(kubectl get pods -n animehot -l app=py-crawler --field-selector=status.phase=Pending --no-headers 2>/dev/null | wc -l)

    # ASG çŠ¶æ€
    ASG_INFO=$(aws autoscaling describe-auto-scaling-groups \
      --auto-scaling-group-names "$ASG_NAME" \
      --region "$AWS_REGION" \
      --query 'AutoScalingGroups[0].{Desired:DesiredCapacity,InService:length(Instances[?LifecycleState==`InService`])}' \
      --output json 2>/dev/null)
    ASG_DESIRED=$(echo "$ASG_INFO" | jq -r '.Desired // 0')
    ASG_INSERVICE=$(echo "$ASG_INFO" | jq -r '.InService // 0')

    # K8s ä¸­çš„ spot èŠ‚ç‚¹æ•°
    K8S_SPOT_NODES=$(kubectl get nodes -l node-role=spot --no-headers 2>/dev/null | wc -l)

    echo "KEDA replicas: $KEDA_REPLICAS"
    echo "Pending pods: $PENDING_PODS"
    echo "ASG: desired=$ASG_DESIRED, inService=$ASG_INSERVICE"
    echo "K8s spot nodes: $K8S_SPOT_NODES"

    # =========================================================
    # 2. æ‰©ç¼©å®¹å†³ç­–
    # =========================================================
    #
    # åœºæ™¯A - æ‰©å®¹: æœ‰ Pending pods ä¸” ASG desired < KEDA replicas
    #   â†’ desired = KEDA_REPLICAS (ä¸€æ¬¡æ€§æ‰©åˆ°ç›®æ ‡)
    #   æ³¨æ„: ä¸ç”¨ K8s èŠ‚ç‚¹æ•°ï¼Œå› ä¸ºèŠ‚ç‚¹åŠ å…¥æœ‰ 60-90s å»¶è¿Ÿ
    #
    # åœºæ™¯A2 - ç­‰å¾…ä¸­: Pending pods ä½† ASG desired >= KEDA replicas
    #   â†’ ä¸æ“ä½œï¼Œç­‰å¾…èŠ‚ç‚¹åŠ å…¥ K8s
    #
    # åœºæ™¯B - åŒæ­¥ç¼©å®¹ (Banè‡ªæ€å): desired > inService ä¸”æ—  Pending
    #   â†’ desired = inService (åŒæ­¥åˆ°å®é™…å€¼)
    #
    # åœºæ™¯C - ä¸»åŠ¨ç¼©å®¹: KEDA replicas < inService ä¸”æ—  Pending
    #   â†’ desired = KEDA_REPLICAS (ä¸€æ¬¡æ€§ç¼©å®¹åˆ°ç›®æ ‡)
    #
    # åœºæ™¯D - å®Œå…¨ç¼©å®¹: KEDA replicas=0 ä¸” inService=0 ä¸” desired>0
    #   â†’ desired = 0 (æ¸…ç†çŠ¶æ€)
    #
    # åœºæ™¯E - æ¸…ç†æ®‹ç•™èŠ‚ç‚¹: K8s æœ‰ NotReady çš„ spot èŠ‚ç‚¹ä½† ASG æ— å¯¹åº”å®ä¾‹
    #   â†’ ä» K8s åˆ é™¤è¿™äº›èŠ‚ç‚¹
    # =========================================================

    # åœºæ™¯A: æ‰©å®¹ - æœ‰ Pending pods ä¸” ASG desired < KEDA éœ€è¦çš„æ•°é‡
    # å…³é”®ï¼šä¸çœ‹ K8s èŠ‚ç‚¹æ•°ï¼Œå› ä¸ºèŠ‚ç‚¹åŠ å…¥æœ‰å»¶è¿Ÿ (60-90s)
    # åªçœ‹ ASG desired æ˜¯å¦è¶³å¤Ÿæ»¡è¶³ KEDA éœ€æ±‚
    if [ "$PENDING_PODS" -gt 0 ] && [ "$ASG_DESIRED" -lt "$KEDA_REPLICAS" ]; then
      NEW_DESIRED=$KEDA_REPLICAS
      echo "â¬†ï¸ Scale UP: Pending pods detected, need more capacity"
      echo "   ASG desired ($ASG_DESIRED) < KEDA replicas ($KEDA_REPLICAS), scaling to $NEW_DESIRED"
      aws autoscaling set-desired-capacity \
        --auto-scaling-group-name "$ASG_NAME" \
        --desired-capacity "$NEW_DESIRED" \
        --region "$AWS_REGION"
      echo "ASG scaled to $NEW_DESIRED"

    # ç­‰å¾…ä¸­: ASG å·²æœ‰è¶³å¤Ÿ desiredï¼Œç­‰å¾…èŠ‚ç‚¹åŠ å…¥ K8s
    elif [ "$PENDING_PODS" -gt 0 ] && [ "$ASG_DESIRED" -ge "$KEDA_REPLICAS" ]; then
      echo "â³ Waiting: ASG desired ($ASG_DESIRED) >= KEDA replicas ($KEDA_REPLICAS)"
      echo "   Pending pods will be scheduled when nodes join K8s (takes 60-90s)"

    # åœºæ™¯B: åŒæ­¥ç¼©å®¹ (èŠ‚ç‚¹ ban è‡ªæ€å, ASG ä»æœ‰ desired > inService çš„å·®å€¼)
    elif [ "$ASG_DESIRED" -gt "$ASG_INSERVICE" ] && [ "$PENDING_PODS" -eq 0 ]; then
      echo "ğŸ”„ Sync DOWN: desired ($ASG_DESIRED) > inService ($ASG_INSERVICE), no pending pods"
      echo "   Node likely self-terminated (ban/IP rotation), syncing desired to $ASG_INSERVICE"
      aws autoscaling set-desired-capacity \
        --auto-scaling-group-name "$ASG_NAME" \
        --desired-capacity "$ASG_INSERVICE" \
        --region "$AWS_REGION"
      echo "ASG synced to $ASG_INSERVICE"

    # åœºæ™¯C: ä¸»åŠ¨ç¼©å®¹ - KEDA éœ€è¦çš„ pod æ•°å°‘äºå½“å‰è¿è¡Œçš„èŠ‚ç‚¹æ•°
    # ä¸€æ¬¡æ€§ç¼©å®¹åˆ°ç›®æ ‡å€¼
    elif [ "$KEDA_REPLICAS" -lt "$ASG_INSERVICE" ] && [ "$PENDING_PODS" -eq 0 ]; then
      NEW_DESIRED=$KEDA_REPLICAS
      if [ "$NEW_DESIRED" -lt 0 ]; then NEW_DESIRED=0; fi

      echo "â¬‡ï¸ Scale DOWN: KEDA needs $KEDA_REPLICAS but have $ASG_INSERVICE nodes"
      echo "   Scaling down to $NEW_DESIRED immediately"
      aws autoscaling set-desired-capacity \
        --auto-scaling-group-name "$ASG_NAME" \
        --desired-capacity "$NEW_DESIRED" \
        --region "$AWS_REGION"
      echo "ASG scaled to $NEW_DESIRED"

    # åœºæ™¯D: å®Œå…¨ç¼©å®¹ (KEDA å†³å®šä¸éœ€è¦ä»»ä½• pod)
    elif [ "$KEDA_REPLICAS" -eq 0 ] && [ "$ASG_INSERVICE" -eq 0 ] && [ "$ASG_DESIRED" -gt 0 ]; then
      echo "â¬‡ï¸ Full scale DOWN: KEDA replicas=0, no inService instances"
      echo "   Cleaning up ASG desired to 0"
      aws autoscaling set-desired-capacity \
        --auto-scaling-group-name "$ASG_NAME" \
        --desired-capacity 0 \
        --region "$AWS_REGION"
      echo "ASG scaled to 0"

    else
      echo "âœ“ No scaling action needed"
    fi

    # åœºæ™¯E: æ¸…ç† K8s ä¸­çš„æ®‹ç•™èŠ‚ç‚¹ (ASG å·²ç»ˆæ­¢ä½† K8s æœªåˆ é™¤)
    if [ "$K8S_SPOT_NODES" -gt "$ASG_INSERVICE" ]; then
      echo "ğŸ§¹ Cleanup: K8s has $K8S_SPOT_NODES spot nodes but ASG only has $ASG_INSERVICE"
      # è·å– NotReady çš„ spot èŠ‚ç‚¹
      NOTREADY_NODES=$(kubectl get nodes -l node-role=spot --no-headers 2>/dev/null | grep -v " Ready" | awk '{print $1}')
      for NODE in $NOTREADY_NODES; do
        echo "   Deleting orphan node: $NODE"
        kubectl delete node "$NODE" --ignore-not-found || true
      done
    fi

    # =========================================================
    # åœºæ™¯F: åƒµå°¸å®ä¾‹æ£€æµ‹ - ASG æœ‰å®ä¾‹ä½† K8s æ²¡æœ‰å¯¹åº”èŠ‚ç‚¹
    # å¯åŠ¨è¶…è¿‡ 5 åˆ†é’Ÿä½†ä»æœªåŠ å…¥ K8s çš„å®ä¾‹è§†ä¸ºåƒµå°¸
    # =========================================================
    if [ "$ASG_INSERVICE" -gt 0 ]; then
      echo "--- Checking for zombie instances ---"

      # è·å– ASG ä¸­çš„ InService å®ä¾‹ ID åˆ—è¡¨
      ASG_INSTANCES=$(aws autoscaling describe-auto-scaling-groups \
        --auto-scaling-group-names "$ASG_NAME" \
        --region "$AWS_REGION" \
        --query 'AutoScalingGroups[0].Instances[?LifecycleState==`InService`].InstanceId' \
        --output text 2>/dev/null | tr '\t' '\n')

      # è·å– K8s ä¸­ Ready çš„ spot èŠ‚ç‚¹åç§° (æ ¼å¼: spot-i-xxx)
      K8S_READY_NODES=$(kubectl get nodes -l node-role=spot --no-headers 2>/dev/null | grep " Ready" | awk '{print $1}' || echo "")

      for INSTANCE_ID in $ASG_INSTANCES; do
        NODE_NAME="spot-${INSTANCE_ID}"

        # æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦åœ¨ K8s ä¸­ä¸” Ready
        if ! echo "$K8S_READY_NODES" | grep -q "^${NODE_NAME}$"; then
          # è·å–å®ä¾‹å¯åŠ¨æ—¶é—´
          LAUNCH_TIME=$(aws ec2 describe-instances \
            --instance-ids "$INSTANCE_ID" \
            --region "$AWS_REGION" \
            --query 'Reservations[0].Instances[0].LaunchTime' \
            --output text 2>/dev/null || echo "")

          if [ -n "$LAUNCH_TIME" ] && [ "$LAUNCH_TIME" != "None" ]; then
            LAUNCH_EPOCH=$(date -d "$LAUNCH_TIME" +%s 2>/dev/null || echo "0")
            NOW=$(date +%s)
            AGE=$((NOW - LAUNCH_EPOCH))

            # è¶…è¿‡ 5 åˆ†é’Ÿ (300ç§’) ä»æœªåŠ å…¥ï¼Œè§†ä¸ºåƒµå°¸
            if [ "$AGE" -gt 300 ]; then
              echo "ğŸ§Ÿ Zombie detected: $INSTANCE_ID (age=${AGE}s, not in K8s Ready nodes)"
              echo "   Terminating zombie instance..."
              aws ec2 terminate-instances \
                --instance-ids "$INSTANCE_ID" \
                --region "$AWS_REGION" 2>/dev/null || true
              # åŒæ—¶æ¸…ç† K8s ä¸­å¯èƒ½å­˜åœ¨çš„ NotReady èŠ‚ç‚¹
              kubectl delete node "$NODE_NAME" --ignore-not-found 2>/dev/null || true
            else
              echo "   Instance $INSTANCE_ID still bootstrapping (age=${AGE}s < 300s)"
            fi
          fi
        fi
      done
    fi

    # =========================================================
    # 3. Ban æ£€æµ‹ - å¤„ç†è¢«å°ç¦çš„èŠ‚ç‚¹
    # =========================================================
    # py-crawler è¢« ban åä¼šå†™æ­»äº¡æŠ¥å‘Šåˆ° Redis
    # æ ¼å¼: {"node_id": "spot-i-xxx", "reason": "banned_403", "timestamp": xxx}
    # éœ€è¦ç»ˆæ­¢è¢« ban çš„å®ä¾‹å¹¶è®© ASG å¯åŠ¨æ–°èŠ‚ç‚¹

    echo "--- Checking for banned nodes ---"

    # è¯»å–æœ€æ–°çš„æ­»äº¡æŠ¥å‘Š
    DEATH_REPORT=$(redis-cli -h "$REDIS_HOST" LINDEX "$REDIS_DEATHS_KEY" 0 2>/dev/null || echo "")

    if [ -n "$DEATH_REPORT" ] && [ "$DEATH_REPORT" != "nil" ]; then
      NODE_ID=$(echo "$DEATH_REPORT" | jq -r '.node_id // empty')
      REASON=$(echo "$DEATH_REPORT" | jq -r '.reason // empty')
      TIMESTAMP=$(echo "$DEATH_REPORT" | jq -r '.timestamp // 0')

      if [ -n "$NODE_ID" ] && [ -n "$REASON" ]; then
        # æ£€æŸ¥æŠ¥å‘Šæ˜¯å¦åœ¨ 5 åˆ†é’Ÿå†…
        NOW=$(date +%s)
        AGE=$((NOW - TIMESTAMP))

        if [ "$AGE" -lt 300 ]; then
          echo "ğŸš¨ Ban detected: node=$NODE_ID, reason=$REASON, age=${AGE}s"

          # ä» node_id (spot-i-xxx) æå– instance_id (i-xxx)
          INSTANCE_ID=$(echo "$NODE_ID" | sed 's/^spot-//')

          if [ -n "$INSTANCE_ID" ]; then
            echo "   Terminating banned instance: $INSTANCE_ID"

            # ç»ˆæ­¢ EC2 å®ä¾‹
            aws ec2 terminate-instances \
              --instance-ids "$INSTANCE_ID" \
              --region "$AWS_REGION" 2>/dev/null || true

            # ä» K8s åˆ é™¤èŠ‚ç‚¹
            kubectl delete node "$NODE_ID" --ignore-not-found || true

            # ä» Redis ç§»é™¤å·²å¤„ç†çš„æŠ¥å‘Š
            redis-cli -h "$REDIS_HOST" LPOP "$REDIS_DEATHS_KEY" >/dev/null 2>&1 || true

            echo "   Banned node terminated, ASG will launch replacement"
          fi
        else
          echo "   Stale death report (age=${AGE}s > 300s), removing"
          redis-cli -h "$REDIS_HOST" LPOP "$REDIS_DEATHS_KEY" >/dev/null 2>&1 || true
        fi
      fi
    else
      echo "   No death reports"
    fi

    # =========================================================
    # 4. Tailscale æ¸…ç† - åˆ é™¤ offline çš„ spot èŠ‚ç‚¹
    # =========================================================
    # ASG å¼ºåˆ¶ç»ˆæ­¢å®ä¾‹æ—¶ï¼Œtailscale-cleanup.service ä¸ä¼šæ‰§è¡Œ
    # éœ€è¦é€šè¿‡ API æ¸…ç†æ®‹ç•™çš„ offline èŠ‚ç‚¹

    if [ -n "$TAILSCALE_API_KEY" ]; then
      echo "--- Cleaning stale Tailscale nodes ---"

      # è·å–å½“å‰æ—¶é—´æˆ³
      NOW=$(date +%s)

      # ç”¨ jq ä¸€æ¬¡æ€§ç­›é€‰å‡ºéœ€è¦åˆ é™¤çš„èŠ‚ç‚¹ (spot-* ä¸” offline è¶…è¿‡ 5 åˆ†é’Ÿ)
      # è¾“å‡ºæ ¼å¼: id hostname age
      STALE_NODES=$(curl -sf -H "Authorization: Bearer $TAILSCALE_API_KEY" \
        "https://api.tailscale.com/api/v2/tailnet/-/devices" 2>/dev/null | \
        jq -r --argjson now "$NOW" '
          .devices[]
          | select(.hostname | startswith("spot-"))
          | (.lastSeen | fromdateiso8601) as $lastEpoch
          | ($now - $lastEpoch) as $age
          | select($age > 300)
          | "\(.id) \(.hostname) \($age)"
        ' 2>/dev/null || echo "")

      if [ -z "$STALE_NODES" ]; then
        echo "   No stale nodes found"
      else
        echo "$STALE_NODES" | while read -r DEV_ID DEV_NAME AGE; do
          if [ -n "$DEV_ID" ]; then
            echo "   Removing stale node: $DEV_NAME (offline ${AGE}s)"
            curl -sf -X DELETE -H "Authorization: Bearer $TAILSCALE_API_KEY" \
              "https://api.tailscale.com/api/v2/device/$DEV_ID" >/dev/null 2>&1 || true
          fi
        done
      fi
    else
      echo "--- Tailscale cleanup skipped (no API key) ---"
    fi

    echo "=== Done ==="

---
# CronJob - æ¯åˆ†é’Ÿæ£€æŸ¥
apiVersion: batch/v1
kind: CronJob
metadata:
  name: spot-asg-scaler
  namespace: kube-system
spec:
  schedule: "* * * * *"  # æ¯åˆ†é’Ÿ
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      activeDeadlineSeconds: 60
      template:
        spec:
          serviceAccountName: spot-asg-scaler
          restartPolicy: OnFailure
          nodeSelector:
            node-role: master
          tolerations:
          - key: "node-role"
            operator: "Equal"
            value: "master"
            effect: "NoSchedule"
          containers:
          - name: scaler
            image: alpine:3.19
            command: ["/bin/sh", "-c"]
            args:
            - |
              # å¿«é€Ÿå®‰è£…ä¾èµ– (~5ç§’)
              apk add --no-cache curl jq bash aws-cli redis > /dev/null 2>&1
              # å®‰è£… kubectl
              curl -sLO "https://dl.k8s.io/release/v1.29.0/bin/linux/amd64/kubectl"
              chmod +x kubectl && mv kubectl /usr/local/bin/
              # è¿è¡Œè„šæœ¬
              /bin/bash /scripts/scale.sh
            env:
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: aws-credentials
                  key: AWS_ACCESS_KEY_ID
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: aws-credentials
                  key: AWS_SECRET_ACCESS_KEY
            - name: TAILSCALE_API_KEY
              valueFrom:
                secretKeyRef:
                  name: tailscale-api
                  key: api-key
                  optional: true
            volumeMounts:
            - name: script
              mountPath: /scripts
          volumes:
          - name: script
            configMap:
              name: spot-asg-scaler-script
              defaultMode: 0755
