# .env.example
# Copy to .env and modify as needed
#
# 生产环境部署:
#   1. cp .env.example .env.prod
#   2. 修改所有密码和密钥
#   3. 设置 DOMAIN_NAME
#   4. 运行 ./deploy/certbot/init-letsencrypt.sh

# =============================================================================
# Production - 生产环境专用
# =============================================================================
# 域名 (用于 Nginx 和 SSL 证书)
DOMAIN_NAME=anime-hot.com

# Let's Encrypt 邮箱 (证书过期通知)
LETSENCRYPT_EMAIL=admin@anime-hot.com

# Let's Encrypt 测试模式 (1=测试, 0=正式)
LETSENCRYPT_STAGING=0

# Admin API Key (保护 /api/v1/admin/* 端点)
ADMIN_API_KEY=your_secure_api_key_here

# =============================================================================
# Application
# =============================================================================
APP_ENV=prod
DEBUG=false
AUTO_MIGRATE=true

# =============================================================================
# MySQL
# =============================================================================
MYSQL_ROOT_PASSWORD=animetop_root_secret
MYSQL_DATABASE=animetop
MYSQL_USER=animetop
MYSQL_PASSWORD=animetop_secret_password
MYSQL_PORT=3306

# =============================================================================
# Redis
# =============================================================================
REDIS_PORT=6379
# 连接池大小 (默认 10)
REDIS_POOL_SIZE=10
# 最小空闲连接数 (默认 2)
REDIS_MIN_IDLE_CONNS=2
# 连接超时 (默认 5s)
REDIS_DIAL_TIMEOUT=5s
# 读取超时 (默认 3s)
REDIS_READ_TIMEOUT=3s
# 写入超时 (默认 3s)
REDIS_WRITE_TIMEOUT=3s

# =============================================================================
# API Server
# =============================================================================
API_PORT=8080

# =============================================================================
# Scheduler (调度器配置)
# =============================================================================
# 基础调度间隔 (权重=1.0时的间隔)
SCHEDULER_BASE_INTERVAL=2h
# 最小间隔 (高权重IP下限)
SCHEDULER_MIN_INTERVAL=1h
# 最大间隔 (低权重IP上限，保证每2小时至少爬取一次)
SCHEDULER_MAX_INTERVAL=2h

# -----------------------------------------------------------------------------
# 爬取深度配置
# -----------------------------------------------------------------------------
# 每次爬取在售页数 (默认 5)
SCHEDULER_PAGES_ON_SALE=5
# 每次爬取已售页数 (默认 5)
SCHEDULER_PAGES_SOLD=5

# =============================================================================
# Analyzer (分析器配置)
# =============================================================================
# Redis 快照 TTL
ANALYZER_SNAPSHOT_TTL=48h

# -----------------------------------------------------------------------------
# 状态机 TTL 配置 (用于商品状态追踪)
# -----------------------------------------------------------------------------
# on_sale 商品 TTL (默认 24h)
# 用于检测新上架，只需覆盖爬取间隔即可
ANALYZER_ITEM_TTL_AVAILABLE=24h

# sold 商品 TTL (默认 48h)
# 需要覆盖冷门 IP sold 商品在可见范围的停留时间 (~33h)
# 防止 sold 商品被重复计入 outflow
ANALYZER_ITEM_TTL_SOLD=48h

# -----------------------------------------------------------------------------
# 预警阈值配置
# -----------------------------------------------------------------------------
# 高出货量预警阈值 (出货量 >= 此值触发 Warning 预警)
# 含义: 短时间内大量商品被卖出，可能是退坑潮信号
ANALYZER_HIGH_OUTFLOW_THRESHOLD=50

# 低流动性预警阈值 (流动性指数 < 此值触发 Info 预警)
# 流动性指数 = outflow / inflow = 出货量 / 进货量
# < 0.3 表示进货多出货少，供过于求，商品卖不动
ANALYZER_LOW_LIQUIDITY_THRESHOLD=0.3

# 高流动性预警阈值 (流动性指数 > 此值触发 Critical 预警)
# > 2.0 表示出货远超进货，可能是爆火或炒作信号
ANALYZER_HIGH_LIQUIDITY_THRESHOLD=2.0

# =============================================================================
# Browser/Crawler (爬虫配置)
# =============================================================================
# 最大并发页面数 (跨任务)
BROWSER_MAX_CONCURRENCY=2
# 每次爬取最大商品数
BROWSER_MAX_FETCH_COUNT=120

# -----------------------------------------------------------------------------
# 单页超时配置 (与页数配置相关)
# -----------------------------------------------------------------------------
# 单页加载超时。任务总超时 ≈ (在售页数 + 已售页数) × 单页超时
# 默认 60s，6页任务总超时约 6 分钟
BROWSER_PAGE_TIMEOUT=60s

# 重启前最大任务数 (防止内存泄漏)
MAX_TASKS=50
# 代理冷却时间
PROXY_COOLDOWN=10m
# 代理失败阈值
PROXY_FAILURE_THRESHOLD=10
# 代理自动切换
PROXY_AUTO_SWITCH=false
# HTTP 代理 (可选)
HTTP_PROXY=

# =============================================================================
# Worker Pool
# =============================================================================
APP_WORKER_POOL_SIZE=2

# =============================================================================
# Grafana Cloud Monitoring (可选)
# 启用监控: docker compose --profile monitoring up -d
# =============================================================================
HOSTNAME=animetop-prod

# Prometheus Remote Write
GRAFANA_CLOUD_PROM_REMOTE_WRITE_URL=https://prometheus-xxx.grafana.net/api/prom/push
GRAFANA_CLOUD_PROM_USERNAME=123456
GRAFANA_CLOUD_PROM_API_KEY=glc_xxx

# Loki (Logs)
GRAFANA_CLOUD_LOKI_URL=https://logs-xxx.grafana.net/loki/api/v1/push
GRAFANA_CLOUD_LOKI_USERNAME=123456
GRAFANA_CLOUD_LOKI_API_KEY=glc_xxx

# =============================================================================
# 配置指南：爬取深度与超时
# =============================================================================
#
# 爬取深度决定每次任务抓取多少页数据：
#   - SCHEDULER_PAGES_ON_SALE: 在售商品页数
#   - SCHEDULER_PAGES_SOLD: 已售商品页数
#   - 总页数 = 在售页数 + 已售页数
#
# 超时配置需要与页数匹配：
#   - BROWSER_PAGE_TIMEOUT: 单页加载超时
#   - 任务总超时 ≈ 总页数 × 单页超时
#
# 配置示例：
#
# 【轻量模式】适合网络稳定、IP数量多的场景
#   SCHEDULER_PAGES_ON_SALE=2
#   SCHEDULER_PAGES_SOLD=2
#   BROWSER_PAGE_TIMEOUT=45s
#   # 总页数: 4页, 任务超时: ~3分钟
#   # 每IP样本: ~480个商品 (120/页 × 4页)
#
# 【标准模式】默认配置，平衡深度与性能 (2H 间隔)
#   SCHEDULER_PAGES_ON_SALE=5
#   SCHEDULER_PAGES_SOLD=5
#   BROWSER_PAGE_TIMEOUT=60s
#   # 总页数: 10页, 任务超时: ~10分钟
#   # 每IP样本: ~1200个商品 (120/页 × 10页)
#
# 【深度模式】适合分析重点IP，获取更多数据
#   SCHEDULER_PAGES_ON_SALE=5
#   SCHEDULER_PAGES_SOLD=5
#   BROWSER_PAGE_TIMEOUT=60s
#   # 总页数: 10页, 任务超时: ~10分钟
#   # 每IP样本: ~1200个商品 (120/页 × 10页)
#
# 【网络慢速模式】适合代理延迟高的场景
#   SCHEDULER_PAGES_ON_SALE=3
#   SCHEDULER_PAGES_SOLD=3
#   BROWSER_PAGE_TIMEOUT=90s
#   # 总页数: 6页, 任务超时: ~9分钟
#
# 注意事项：
#   1. 页数越多，数据越完整，但任务耗时越长
#   2. 超时设置过短会导致任务失败率上升
#   3. 超时设置过长会浪费资源（任务失败时等待过久）
#   4. 建议根据实际网络环境和 IP 数量调整
#   5. 可通过 Grafana 监控 animetop_task_processing_duration_seconds 观察实际耗时
